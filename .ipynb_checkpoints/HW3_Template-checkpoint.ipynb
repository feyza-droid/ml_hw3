{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn import decomposition\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#suppress warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLG527E - Machine Learning, Homework 3\n",
    "\n",
    "In this homework, you are supposed to implement following parts:\n",
    "     \n",
    "- **Part 1: solve an SVM optimization problem by hand (50 points)**\n",
    "\n",
    "- **Part 2: Federate a logistic regression classifier (40 points)**\n",
    "\n",
    "- **Part 3: practice feature selection (10 points)**\n",
    "     - Refer to Machine Learning Blinks 10 and 11 for this part:\n",
    "     - ML Blinks 10: https://www.youtube.com/watch?v=laeth5oT9YM&list=PLug43ldmRSo1LDlvQOPzgoJ6wKnfmzimQ\n",
    "     - ML Blinks 11: https://www.youtube.com/watch?v=mRmVKNklE9I&list=PLug43ldmRSo1LDlvQOPzgoJ6wKnfmzimQ \n",
    " \n",
    " \n",
    " \n",
    " ### Important Notes:\n",
    "   - Please complete this template and include any other necessary materials (screenshots of your handwritten solutions etc.) into the HW3 folder. Then zip it again and submit to Ninova.\n",
    "   - At Part 1, you can upload the screenshots of your handwritten solutions to the Notebook. But please be sure that your solutions are neat and can be read properly.\n",
    "   - For the Part 2, you will Federate a classifier across 20 datasets. Check the paper in Part 2.2 for more details. \n",
    "   - For the Part 3, you should implement feature selection from scratch however can use scikit-learn built-in functions for training the SVM.\n",
    "   - You can ask your questions via kamard@itu.edu.tr \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Solving SVM optimization by hand (50 points)\n",
    "\n",
    "You can insert the screenshots of your handwritten solution on Jupyter Notebook. For an example, check the cells including images. Do not forget to include your solution image file into the submitted .zip file.\n",
    "\n",
    "Some reminders for the question:\n",
    "\n",
    " - Lagrangian to optimize: $\\mathcal{L}_{primal} = \\sum_{i=1}^{n} a_{i} - \\frac{1}{2} [\\sum_{i=1}^{n}\\sum_{j=1}^{n}\\alpha_{i}\\alpha_{j}y_{i}y_{j}x_{i}^{T}x^{j}] $ \n",
    "\n",
    "\n",
    "- Constraint: $\\sum_{i=1}^{n} \\alpha_{i} y_{i} = 0$\n",
    "\n",
    "\n",
    "- Optimal parameter: $w^{*} = \\sum_{i=1}^{n} \\alpha_{i} y_{i} x^{i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.1 (25 points)\n",
    "\n",
    "<p style=\"float: left;\"><img src=\"images/Part1-1.png\" width = \"200\"></p>\n",
    "        \n",
    "        Given the two following training samples (n=2), provide below a step-by-step solution\n",
    "        to estimate the optimal parameters (w and b) of the hyperplane separating the two classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.1 Solution\n",
    "\n",
    "<p style=\"float: left;\"><img src=\"images/Part1.1.1.jpeg\" width = \"200\"></p>\n",
    "<p style=\"float: left;\"><img src=\"images/Part1.1.2.jpeg\" width = \"200\"></p>\n",
    "<p style=\"float: left;\"><img src=\"images/Part1.1.3.jpeg\" width = \"200\"></p>\n",
    "<p style=\"float: left;\"><img src=\"images/Part1.1.4.jpeg\" width = \"200\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.2 (15 points) \n",
    "If we add a third training point $x_3 = \\left [\\begin{matrix} -4 \\\\ 4 \\end{matrix}\\right] $, will that impact the hyperplane estimated using points $x_1$ and $x_2$? Answer this considering two cases where label for $x_3$ is (1) $y_3 = +1 $, (2) $y_3 = -1 $ and justify. You do not need to solve Lagrangian again, justify your answer drawing the hyperplanes and giving explanations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.2 Solution\n",
    "\n",
    "<p style=\"float: left;\"><img src=\"images/Part1.2.1.jpeg\" width = \"200\"></p>\n",
    "<p style=\"float: left;\"><img src=\"images/Part1.2.2.jpeg\" width = \"200\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.3 (10 points)\n",
    "Explain how to classify the point $x_{test} = \\left [\\begin{matrix} -4 \\\\ -3 \\end{matrix}\\right] $ using the estimated model at Part 1.1. What is the predicted label of $x_{test}$? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.3 Solution\n",
    "\n",
    "<p style=\"float: left;\"><img src=\"images/Part1.3.1.jpeg\" width = \"200\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Federate a logistic regression classifier across 20 datasets (40 points)\n",
    "\n",
    "We set out to classify two digits from the MNIST dataset: digit 0 to which we assign the label 0 and digit 1 to which we assign the label 1 using the code of the logistic regression based on the softmax loss. You are allowed to use built-in functions from scikit-learn in the specified parts below, which you can install via one of the following commands (depending on which one you use):\n",
    "\n",
    "        > python3 -m pip install scikit-learn\n",
    "        > conda install -c conda-forge scikit-learn\n",
    "\n",
    "We have 20 local datasets distributed across 20 clients and 1 global test dataset left for testing. The function **parse_mnist_into_clients** in the following cell creates the datasets from the shared files. You do NOT need to change the function. You can simply run the following cell and it will load the datasets for you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_mnist_into_clients():\n",
    "    '''\n",
    "    Parses the MNIST data files into 20 local datasets for clients and 1 global test dataset. \n",
    "    Do NOT change this function!\n",
    "    \n",
    "    \n",
    "    Outputs:\n",
    "    \n",
    "    local_datasets_data: The MNIST data of the local 20 dataset\n",
    "    local_datasets_label: Labels of the 20 local dataset. local_datasets_data[i] corresponds to local_datasets_label[i]\n",
    "    test_data : Global Test Data\n",
    "    test_label: Labels of the global test data\n",
    "    '''\n",
    "    data = np.load('mnist_data.npy')\n",
    "    labels = np.load('mnist_labels.npy')\n",
    "    local_datasets_data  = []\n",
    "    local_datasets_label = []\n",
    "    \n",
    "    for i in range(20):\n",
    "        local_datasets_data.append(np.copy(data[i*703:(i+1)*703]))\n",
    "        local_datasets_label.append(np.copy(labels[i*703:(i+1)*703]))\n",
    "    \n",
    "    test_data = np.copy(data[14060:])  \n",
    "    test_labels = np.copy(labels[14060:])\n",
    "    \n",
    "    return local_datasets_data, local_datasets_label, test_data, test_labels\n",
    "\n",
    "# Load the data\n",
    "client_data, client_label, test_data, test_label = parse_mnist_into_clients()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple example code of the logistic classifier using softmax loss is included below. Use this code to federate the learning of the 20 clients and test their local models on the left-out test dataset. Note that the code below is a very simple logistic regression code and the hyper parameters is not optimized. Feel free to modify it depending on what you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/ (1 + np.exp(-x))\n",
    "\n",
    "def calculate_grad(X, y, w): # gradient of the loss function least square cost by using sigmoid(xw + b)\n",
    "    s = sigmoid(-y * (X @ w))\n",
    "    grad = -X.T @ (s * y)\n",
    "    grad = np.mean(grad, axis=1, keepdims=True) # mean error across samples\n",
    "    return grad\n",
    "\n",
    "def client_update(k, w, E): # this is designed for B equals infinity (select all training data of that client)\n",
    "    alpha = 10**-1 # learning rate\n",
    "    X = client_data_reduced[k] # kth client can only see the kth data \n",
    "    y = client_label[k] # kth client can only see the kth labels\n",
    "    \n",
    "    for epoch in range(E):\n",
    "        grad = calculate_grad(X,y,w) # gradient of the loss function wrt to w\n",
    "        w = w - alpha * grad # update rule of gradient descent\n",
    "        \n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.1 (10 points)\n",
    "\n",
    "Use built-in PCA from scikit-learn library to reduce the dimensionality of the training and testing samples to only two dimension (PC1 and PC2). PS: Watch <a href='https://www.youtube.com/watch?v=mRmVKNklE9I&list=PLug43ldmRSo1LDlvQOPzgoJ6wKnfmzimQ&index=45'>lecture 11</a> (beware of the eavesdropping phenomenon!). Note also that PCA should be applied to each client independently. In federated learning, clients never share data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pca(data):\n",
    "    pca = decomposition.PCA(n_components=2)\n",
    "    pca.fit(data)\n",
    "    reduced_data = pca.transform(data)\n",
    "    return reduced_data\n",
    "\n",
    "# for training\n",
    "# client_data_reduced data structure is used to hold all clients but in client update each client is only allowed to reach kth elements\n",
    "client_data_reduced = []\n",
    "for X in client_data: # do this for each different client\n",
    "    X_reduced = apply_pca(X)\n",
    "    client_data_reduced.append(X_reduced)\n",
    "    \n",
    "# for testing #TODO: should the testing data be independent of training\n",
    "test_data_reduced = apply_pca(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.2 (20 points)\n",
    "\n",
    "From now on we will use the reduced 2-dimensional training and test datasets. Train a logistic classifier on the reduced 2-dimensional dataset for each client, independently, send the model weights to the server, aggregate and broadcast back to all clients.\n",
    "\n",
    "Basically, implement the **FederatedAveraging** algorithm in **(https://arxiv.org/pdf/1602.05629.pdf)** for B = infinity (i.e., each client will be trained on all its local training samples). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def server(K, E, number_of_pca_dim, max_round, test_every_round):    \n",
    "    client_weights = np.zeros((K, number_of_pca_dim, 1)) # (20, 2, 1)\n",
    "    w_0 = np.random.randn(number_of_pca_dim,1)\n",
    "    \n",
    "    w_t = w_0\n",
    "    acc_list = []\n",
    "    for t in range(max_round): # at each round weights of the server is updated\n",
    "        for k in range(K): # for each client\n",
    "            client_weights[k] = client_update(k, w_t, E)\n",
    "            \n",
    "        w_t = np.mean(client_weights, axis=0) # update server weights by getting mean weights of all clients, since each client has same number of samples, I didn't use weighted weights (s.t. n_k/n)\n",
    "        \n",
    "        if t % test_every_round == 0:\n",
    "            acc = test_logistic_classifier(w_t, test_data_reduced, test_label) # test with the lastly updated weights\n",
    "            acc_list.append(acc)\n",
    "            \n",
    "    return acc_list\n",
    "    \n",
    "def federated_averaging(K, E, number_of_pca_dim, max_round, test_every_round):\n",
    "    acc_list = server(K, E, number_of_pca_dim, max_round, test_every_round)\n",
    "    return acc_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.3 (10 points)\n",
    "\n",
    "Test the global (aggregated model) on the left-out test dataset. Plot the test classification accuracy on the global dataset against the number of communication rounds for E = 1, 5 and 10. You might need to use a small number of communication rounds if the convergence is fast. Note that B is always set to infinity. Check out Figure 2 in the paper for more details. What do you notice? Discuss your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_logistic_classifier(w, test_data_reduced, test_label):\n",
    "    preds = sigmoid(np.dot(test_data_reduced, w))\n",
    "\n",
    "    correct = 0\n",
    "    n_test_samples = len(test_label)\n",
    "    for i in range(n_test_samples):\n",
    "        if test_label[i] == preds[i]:\n",
    "            correct += 1\n",
    "                \n",
    "    acc = correct/n_test_samples\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing at [  10.   20.   30.   40.   50.   60.   70.   80.   90.  100.  110.  120.\n",
      "  130.  140.  150.  160.  170.  180.  190.  200.  210.  220.  230.  240.\n",
      "  250.  260.  270.  280.  290.  300.  310.  320.  330.  340.  350.  360.\n",
      "  370.  380.  390.  400.  410.  420.  430.  440.  450.  460.  470.  480.\n",
      "  490.  500.  510.  520.  530.  540.  550.  560.  570.  580.  590.  600.\n",
      "  610.  620.  630.  640.  650.  660.  670.  680.  690.  700.  710.  720.\n",
      "  730.  740.  750.  760.  770.  780.  790.  800.  810.  820.  830.  840.\n",
      "  850.  860.  870.  880.  890.  900.  910.  920.  930.  940.  950.  960.\n",
      "  970.  980.  990. 1000. 1010. 1020. 1030. 1040. 1050. 1060. 1070. 1080.\n",
      " 1090. 1100. 1110. 1120. 1130. 1140. 1150. 1160. 1170. 1180. 1190. 1200.\n",
      " 1210. 1220. 1230. 1240. 1250. 1260. 1270. 1280. 1290. 1300. 1310. 1320.\n",
      " 1330. 1340. 1350. 1360. 1370. 1380. 1390. 1400. 1410. 1420. 1430. 1440.\n",
      " 1450. 1460. 1470. 1480. 1490. 1500. 1510. 1520. 1530. 1540. 1550. 1560.\n",
      " 1570. 1580. 1590. 1600. 1610. 1620. 1630. 1640. 1650. 1660. 1670. 1680.\n",
      " 1690. 1700. 1710. 1720. 1730. 1740. 1750. 1760. 1770. 1780. 1790. 1800.\n",
      " 1810. 1820. 1830. 1840. 1850. 1860. 1870. 1880. 1890. 1900. 1910. 1920.\n",
      " 1930. 1940. 1950. 1960. 1970. 1980. 1990. 2000.] communication rounds.\n",
      "\n",
      "Testing acc E=1 [0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778]\n",
      "\n",
      "\n",
      "Testing acc E=5 [0.022222222222222223, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778, 0.002777777777777778]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing acc E=10 [0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222, 0.9972222222222222]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAABQAElEQVR4nO3de1wU5f4H8M8uwnKTBeSu3BSviKKYhGaokYhKmh5FswRPh7xnkqV0StFKzPJyTih5TMWTpmahmSmliOWFvOMlLyleMF28AyIKAs/vD3/McQORhYVdxs/79dqX7jPPzHxnB9mPM8/MKIQQAkREREQyoTR0AURERET6xHBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcEMkc1FRUfDy8jJ0GXp34cIFKBQKJCUlGboUo7Bjxw4oFArs2LHD0KUQGRzDDZEBJSUlQaFQVPiaOnWqocvTi0WLFhlNANm8eTMUCgXc3NxQWlpq6HKIqJY0MHQBRATMnDkT3t7eWm1t27Y1UDX6tWjRIjg4OCAqKsrQpWDVqlXw8vLChQsXsH37doSEhBi6JL15/vnnce/ePZiZmRm6FCKDY7ghMgJhYWHo1KmToct4IiEE7t+/DwsLC0OXorO7d+/i+++/R3x8PJYvX45Vq1bVebipzc9PqVTC3Nxc78slqo94WoqoHtiyZQu6desGKysrNGzYEH379sXvv/9ert+GDRvQtm1bmJubo23btli/fn2FyystLcWCBQvg6+sLc3NzODs7Y9SoUbh9+7ZWPy8vL/Tr1w8//fQTOnXqBAsLCyxevBgAsHz5cvTs2RNOTk5QqVRo06YNEhMTy83/+++/45dffpFOt3Xv3l2anpOTg7feegvu7u5QqVTw8fHBJ598Uu6UUU5ODqKioqBWq2Fra4vIyEjk5OTo9BmuX78e9+7dw+DBgzF06FAkJyfj/v370vS2bduiR48eFX5WjRs3xt/+9rc6//zK1hUXFwc3NzdYWlqiR48eOHHiBLy8vLSOhlU05qZ79+5o27YtTpw4gR49esDS0hKNGzfGnDlzyq3n4sWLeOmll2BlZQUnJydMmjQJP/30E8fxUL3EIzdERiA3Nxc3btzQanNwcAAAfPXVV4iMjERoaCg++eQTFBQUIDExEc899xwOHz4sDRb++eefMWjQILRp0wbx8fG4efMmRo4ciSZNmpRb36hRo5CUlISRI0fizTffxPnz55GQkIDDhw9j9+7dMDU1lfqePn0aw4YNw6hRoxAdHY2WLVsCABITE+Hr64uXXnoJDRo0wA8//ICxY8eitLQU48aNAwAsWLAAEyZMgLW1Nf75z38CAJydnQEABQUFCA4OxuXLlzFq1Ch4eHhgz549iI2NhUajwYIFCwA8PNrRv39/7Nq1C6NHj0br1q2xfv16REZG6vQZr1q1Cj169ICLiwuGDh2KqVOn4ocffsDgwYMBABEREYiLi0N2djZcXFyk+Xbt2oUrV65g6NChdf75AUBsbCzmzJmD8PBwhIaG4siRIwgNDdUKZpW5ffs2evfujYEDB2LIkCH49ttvMWXKFPj5+SEsLAzAw6NaPXv2hEajwcSJE+Hi4oKvv/4aaWlpOn3GREZDEJHBLF++XACo8CWEEHfu3BG2trYiOjpaa77s7GyhVqu12v39/YWrq6vIycmR2n7++WcBQHh6ekptO3fuFADEqlWrtJaZkpJSrt3T01MAECkpKeVqLygoKNcWGhoqmjZtqtXm6+srgoODy/X98MMPhZWVlfjjjz+02qdOnSpMTExEVlaWEEKIDRs2CABizpw5Up/i4mLRrVs3AUAsX7683LL/6urVq6JBgwZiyZIlUluXLl1E//79pfenT58WAMTnn3+uNe/YsWOFtbW1tL11+fllZ2eLBg0aiAEDBmj1i4uLEwBEZGSk1JaWliYAiLS0NKktODhYABD//e9/pbbCwkLh4uIiBg0aJLXNnTtXABAbNmyQ2u7duydatWpVbplE9QFPSxEZgYULF2Lr1q1aLwDYunUrcnJyMGzYMNy4cUN6mZiYIDAwUPqftUajQUZGBiIjI6FWq6Xlvvjii2jTpo3WutatWwe1Wo0XX3xRa5kBAQGwtrYu9791b29vhIaGlqv50XEjZUeegoODce7cOeTm5j5xm9etW4du3brBzs5Oq46QkBCUlJTg119/BfDwCqcGDRpgzJgx0rwmJiaYMGHCE9dRZs2aNVAqlRg0aJDUNmzYMGzZskU6ldSiRQv4+/tj7dq1Up+SkhJ8++23CA8Pl7a3Lj+/1NRUFBcXY+zYsVrz6rLt1tbWePXVV6X3ZmZm6Ny5M86dOye1paSkoHHjxnjppZekNnNzc0RHR1d5PUTGhKeliIxA586dKxxQfObMGQBAz549K5zPxsYGwMPxEgDQvHnzcn1atmyJQ4cOaS0zNzcXTk5OFS7z2rVrWu//ehVXmd27d2P69OlIT09HQUGB1rTc3FytkFWRM2fO4OjRo3B0dKy0josXL8LV1RXW1tbltquqVq5cic6dO+PmzZu4efMmAKBDhw4oKirCunXr8MYbbwB4eGrqvffew+XLl9G4cWPs2LED165dQ0REhFbddfX5le1XHx8fren29vaws7Or0rY3adIECoVCq83Ozg5Hjx6V3l+8eBHNmjUr1++v6yWqLxhuiIxY2cDar776SmscSJkGDXT/J1xaWgonJyesWrWqwul/DRsVXdmTmZmJF154Aa1atcK8efPg7u4OMzMzbN68GfPnz6/SPWRKS0vx4osv4t13361weosWLaqwNU925swZ7N+/H0DF4W/VqlVa4SY2Nhbr1q3DW2+9hW+++QZqtRq9e/fWqtsYPr+qMjExqbBdCKG3dRAZG4YbIiPWrFkzAICTk1Olly17enoC+N+RnkedPn263DK3bduGrl27VvuS5B9++AGFhYXYuHEjPDw8pPaKBqD+9WjAo3Xk5+c/8XJsT09PpKamIj8/X+vozV+363FWrVoFU1NTfPXVV+W+6Hft2oV///vfyMrKgoeHB7y9vdG5c2esXbsW48ePR3JyMgYMGACVSqVVd119fmX79ezZs1pHgG7evFnuyqya8PT0xIkTJyCE0NpfZ8+e1ds6iOoSx9wQGbHQ0FDY2Nhg1qxZePDgQbnp169fBwC4urrC398fK1as0BrvsnXrVpw4cUJrniFDhqCkpAQffvhhueUVFxdX6RLrspDw6P/+c3NzsXz58nJ9raysKlzmkCFDkJ6ejp9++qnctJycHBQXFwMA+vTpg+LiYq3LpEtKSvD5558/sU7gYbjp1q0bIiIi8Le//U3r9c477wAAVq9eLfWPiIjAb7/9hmXLluHGjRtap6TK6q6rz++FF15AgwYNyl0inpCQ8MR16CI0NBSXL1/Gxo0bpbb79+9jyZIlel0PUV3hkRsiI2ZjY4PExES89tpr6NixI4YOHQpHR0dkZWXhxx9/RNeuXaUvuvj4ePTt2xfPPfcc/v73v+PWrVv4/PPP4evri/z8fGmZwcHBGDVqFOLj45GRkYFevXrB1NQUZ86cwbp16/Cvf/1L654uFenVqxfMzMwQHh6OUaNGIT8/H0uWLIGTkxM0Go1W34CAACQmJuKjjz6Cj48PnJyc0LNnT7zzzjvYuHEj+vXrh6ioKAQEBODu3bs4duwYvv32W1y4cAEODg4IDw9H165dMXXqVFy4cAFt2rRBcnJylQYt7927F2fPnsX48eMrnN64cWN07NgRq1atwpQpUwA8DC+TJ0/G5MmTYW9vX+7IUl1+fs7Ozpg4cSLmzp2Ll156Cb1798aRI0ewZcsWODg4PPaomK5GjRqFhIQEDBs2DBMnToSrqytWrVol3RRQX+shqjOGvViL6OlWdin4/v37K+2XlpYmQkNDhVqtFubm5qJZs2YiKipKHDhwQKvfd999J1q3bi1UKpVo06aNSE5OFpGRkVqXgpf5z3/+IwICAoSFhYVo2LCh8PPzE++++664cuWK1MfT01P07du3wpo2btwo2rVrJ8zNzYWXl5f45JNPxLJlywQAcf78ealfdna26Nu3r2jYsKEAoHVZ+J07d0RsbKzw8fERZmZmwsHBQXTp0kV89tlnoqioSOp38+ZN8dprrwkbGxuhVqvFa6+9Jg4fPvzES8EnTJggAIjMzMzH9im7rPrIkSNSW9euXQUA8Y9//OOx89XV51dcXCw++OAD4eLiIiwsLETPnj3FyZMnRaNGjcTo0aOlfo+7FNzX17fcuiv6mTh37pzo27evsLCwEI6OjuLtt98W3333nQAgfvvtt8d+DkTGSCEER5UREdUnOTk5sLOzw0cffSTdHLE2LFiwAJMmTcKff/6Jxo0b19p6iPSNY26IiIzYvXv3yrWV3b350UdZ6Hs99+/fx+LFi9G8eXMGG6p3OOaGiMiIrV27FklJSejTpw+sra2xa9curF69Gr169ULXrl31tp6BAwfCw8MD/v7+yM3NxcqVK3Hq1KnHXvJOZMwYboiIjFi7du3QoEEDzJkzB3l5edIg448++kiv6wkNDcWXX36JVatWoaSkBG3atMGaNWvKXS1GVB9wzA0RERHJCsfcEBERkaww3BAREZGsPHVjbkpLS3HlyhU0bNiQN6YiIiKqJ4QQuHPnDtzc3KBUVn5s5qkLN1euXIG7u7uhyyAiIqJquHTpEpo0aVJpn6cu3DRs2BDAww/HxsbGwNUQERFRVeTl5cHd3V36Hq/MUxduyk5F2djYMNwQERHVM1UZUsIBxURERCQrDDdEREQkKww3REREJCsMN0RERCQrDDdEREQkKww3REREJCsMN0RERCQrDDdEREQkKww3REREJCsGDTe//vorwsPD4ebmBoVCgQ0bNjxxnh07dqBjx45QqVTw8fFBUlJSrddJRERE9YdBw83du3fRvn17LFy4sEr9z58/j759+6JHjx7IyMjAW2+9hX/84x/46aefarlSIiIiqi8M+mypsLAwhIWFVbn/F198AW9vb8ydOxcA0Lp1a+zatQvz589HaGhobZVJRERE9Ui9enBmeno6QkJCtNpCQ0Px1ltvPXaewsJCFBYWSu/z8vJqpTYhgIKCWlk0ERFRvWNpCVThGZe1ol6Fm+zsbDg7O2u1OTs7Iy8vD/fu3YOFhUW5eeLj4zFjxoxar62gALC2rvXVEBER1Qv5+YCVlWHWLfurpWJjY5Gbmyu9Ll26ZOiSiIiIqBbVqyM3Li4uuHr1qlbb1atXYWNjU+FRGwBQqVRQqVS1Xpul5cOUSkRERA+/Fw2lXoWboKAgbN68Watt69atCAoKMlBF/6NQGO7wGxEREf2PQU9L5efnIyMjAxkZGQAeXuqdkZGBrKwsAA9PKY0YMULqP3r0aJw7dw7vvvsuTp06hUWLFuGbb77BpEmTDFE+ERERGSGDhpsDBw6gQ4cO6NChAwAgJiYGHTp0wLRp0wAAGo1GCjoA4O3tjR9//BFbt25F+/btMXfuXHz55Ze8DJyIiIgkCiGEMHQRdSkvLw9qtRq5ubmwsbExdDlERERUBbp8f8v+aikiIiJ6ujDcEBERkaww3BAREZGsMNwQERGRrDDcEBERkaww3BAREZGsMNwQERGRrDDcEBERkaww3BAREZGsMNwQERGRrDDcEBERkaww3BAREZGsMNwQERGRrDDcEBERkaww3BAREZGsMNwQERGRrDDcEBERkaww3BAREZGsMNwQERGRrDDcEBERkaww3BAREZGsMNwQERGRrDDcEBERkaww3BAREZGsMNwQERGRrDDcEBERkaww3BAREZGsMNwQERGRrDDcEBERkaww3BAREZGsMNwQERGRrDDcEBERkaww3BAREZGsMNwQERGRrDDcEBERkaww3BAREZGsMNwQERGRrDDcEBERkaww3BAREZGsMNwQERGRrDDcEBERkaww3BAREZGsMNwQERGRrDDcEBERkaww3BAREZGsMNwQERGRrDDcEBERkaww3BAREZGsMNwQERGRrDDcEBERkaww3BAREZGsMNwQERGRrDDcEBERkaww3BAREZGsMNwQERGRrDDcEBERkawYPNwsXLgQXl5eMDc3R2BgIPbt21dp/wULFqBly5awsLCAu7s7Jk2ahPv379dRtURERGTsDBpu1q5di5iYGEyfPh2HDh1C+/btERoaimvXrlXY/+uvv8bUqVMxffp0nDx5EkuXLsXatWvx3nvv1XHlREREZKwMGm7mzZuH6OhojBw5Em3atMEXX3wBS0tLLFu2rML+e/bsQdeuXfHKK6/Ay8sLvXr1wrBhw554tIeIiIieHgYLN0VFRTh48CBCQkL+V4xSiZCQEKSnp1c4T5cuXXDw4EEpzJw7dw6bN29Gnz596qRmIiIiMn4NDLXiGzduoKSkBM7Ozlrtzs7OOHXqVIXzvPLKK7hx4waee+45CCFQXFyM0aNHV3paqrCwEIWFhdL7vLw8/WwAERERGSWDDyjWxY4dOzBr1iwsWrQIhw4dQnJyMn788Ud8+OGHj50nPj4earVaerm7u9dhxURERFTXFEIIYYgVFxUVwdLSEt9++y0GDBggtUdGRiInJwfff/99uXm6deuGZ599Fp9++qnUtnLlSrzxxhvIz8+HUlk+q1V05Mbd3R25ubmwsbHR70YRERFRrcjLy4Nara7S97fBjtyYmZkhICAAqampUltpaSlSU1MRFBRU4TwFBQXlAoyJiQkA4HEZTaVSwcbGRutFRERE8mWwMTcAEBMTg8jISHTq1AmdO3fGggULcPfuXYwcORIAMGLECDRu3Bjx8fEAgPDwcMybNw8dOnRAYGAgzp49iw8++ADh4eFSyCEiIqKnm0HDTUREBK5fv45p06YhOzsb/v7+SElJkQYZZ2VlaR2pef/996FQKPD+++/j8uXLcHR0RHh4OD7++GNDbQIREREZGYONuTEUXc7ZERERkXGoF2NuiIiIiGoDww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREcmKzuFm+vTpuHjxYm3UQkRERFRjOoeb77//Hs2aNcMLL7yAr7/+GoWFhbVRFxEREVG16BxuMjIysH//fvj6+mLixIlwcXHBmDFjsH///tqoj4iIiEgn1Rpz06FDB/z73//GlStXsHTpUvz555/o2rUr2rVrh3/961/Izc3Vd51EREREVVKjAcVCCDx48ABFRUUQQsDOzg4JCQlwd3fH2rVr9VUjERERUZVVK9wcPHgQ48ePh6urKyZNmoQOHTrg5MmT+OWXX3DmzBl8/PHHePPNN/VdKxEREdETKYQQQpcZ/Pz8cOrUKfTq1QvR0dEIDw+HiYmJVp8bN27AyckJpaWlei1WH/Ly8qBWq5GbmwsbGxtDl0NERERVoMv3dwNdFz5kyBD8/e9/R+PGjR/bx8HBwSiDDREREcmfzqelPvjgg0qDja4WLlwILy8vmJubIzAwEPv27au0f05ODsaNGwdXV1eoVCq0aNECmzdv1ls9REREVL/pHG4GDRqETz75pFz7nDlzMHjwYJ2WtXbtWsTExGD69Ok4dOgQ2rdvj9DQUFy7dq3C/kVFRXjxxRdx4cIFfPvttzh9+jSWLFmi17BFRERE9ZvOY24cHR2xfft2+Pn5abUfO3YMISEhuHr1apWXFRgYiGeeeQYJCQkAgNLSUri7u2PChAmYOnVquf5ffPEFPv30U5w6dQqmpqa6lC3hmBsiIqL6p1bH3OTn58PMzKxcu6mpKfLy8qq8nKKiIhw8eBCxsbFSm1KpREhICNLT0yucZ+PGjQgKCsK4cePw/fffw9HREa+88gqmTJlSblBzmcLCQq27KOtSIxER1a2SkhI8ePDA0GWQgZiZmUGprPljL3UON35+fli7di2mTZum1b5mzRq0adOmysu5ceMGSkpK4OzsrNXu7OyMU6dOVTjPuXPnsH37dgwfPhybN2/G2bNnMXbsWDx48ADTp0+vcJ74+HjMmDGjynUREVHdE0IgOzsbOTk5hi6FDEipVMLb27vCgyi60DncfPDBBxg4cCAyMzPRs2dPAEBqaipWr16NdevW1aiYJyktLYWTkxP+85//wMTEBAEBAbh8+TI+/fTTx4ab2NhYxMTESO/z8vLg7u5eq3USEZFuyoKNk5MTLC0toVAoDF0S1bHS0lJcuXIFGo0GHh4eNfoZ0DnchIeHY8OGDZg1axa+/fZbWFhYoF27dti2bRuCg4OrvBwHBweYmJiUG6Nz9epVuLi4VDiPq6srTE1NtU5BtW7dGtnZ2SgqKqow6alUKqhUqirXRUREdaukpEQKNo0aNTJ0OWRAjo6OuHLlCoqLi6s9thao5h2K+/bti927d+Pu3bu4ceMGtm/frlOwAR6eVwsICEBqaqrUVlpaitTUVAQFBVU4T9euXXH27Fmte+j88ccfcHV1rfEhLCIiMoyyMTaWlpYGroQMrey7vKSkpEbLqfmonRqIiYnBkiVLsGLFCpw8eRJjxozB3bt3MXLkSADAiBEjtAYcjxkzBrdu3cLEiRPxxx9/4Mcff8SsWbMwbtw4Q20CERHpCU9Fkb5+BnQ+LVVSUoL58+fjm2++QVZWFoqKirSm37p1q8rLioiIwPXr1zFt2jRkZ2fD398fKSkp0iDjrKwsrVHT7u7u+OmnnzBp0iS0a9cOjRs3xsSJEzFlyhRdN4OIiIhkSucjNzNmzMC8efMQERGB3NxcxMTEYODAgVAqlYiLi9O5gPHjx+PixYsoLCzE3r17ERgYKE3bsWMHkpKStPoHBQXht99+w/3795GZmYn33nvvsZeBExER1TdxcXHw9/fXaZ6CggIMGjQINjY2UCgUT/1VZzqHm1WrVmHJkiV4++230aBBAwwbNgxffvklpk2bht9++602aiQiIjJKUVFRUCgU0qtRo0bo3bs3jh49Wu1lTp48WWs8alWsWLECO3fuxJ49e6DRaKBWq8v1SUpK0qq17GVubl7tWj/++GN06dIFlpaWsLW1rfZy9E3ncJOdnS3dndja2hq5ubkAgH79+uHHH3/Ub3VERERGrnfv3tBoNNBoNEhNTUWDBg3Qr1+/ai/P2tpa56vGMjMz0bp1a7Rt2xYuLi6PHbtiY2Mj1Vr2unjxYrVrLSoqwuDBgzFmzJhqL6M26BxumjRpAo1GAwBo1qwZfv75ZwDA/v37eck1ERE9dVQqFVxcXODi4gJ/f39MnToVly5dwvXr16u1vL+eloqKisKAAQPw2WefwdXVFY0aNcK4ceOkq8y6d++OuXPn4tdff4VCoUD37t0fu2yFQiHVWvb66810dTFjxgxMmjSp3COZDE3nAcUvv/wyUlNTERgYiAkTJuDVV1/F0qVLkZWVhUmTJtVGjURE9LQRAigoqPv1WloCNbhiJz8/HytXroSPj4/W0RdfX99Kj5B069YNW7Zseez0tLQ0uLq6Ii0tDWfPnkVERAT8/f0RHR2N5ORkTJ06FcePH0dycnKNbo0ya9YszJo1q9I+J06cgIeHR7XXURd0DjezZ8+W/h4REQFPT0/s2bMHzZs3R3h4uF6LIyKip1RBAWBtXffrzc8HrKx0mmXTpk2w/v9a7969C1dXV2zatEnrat/NmzdX+swsCwuLStdhZ2eHhIQEmJiYoFWrVujbty9SU1MRHR0Ne3t7WFpawszM7LE3wS2Tm5sr1Vrm0WA1evRoDBkypNJluLm5VTrdGOgUbh48eIBRo0bhgw8+gLe3NwDg2WefxbPPPlsrxRERERm7Hj16IDExEQBw+/ZtLFq0CGFhYdi3bx88PT0BQPqzunx9fbWuDHZ1dcWxY8d0Xk7Dhg1x6NAhrbZHg5W9vT3s7e2rX6iR0CncmJqa4rvvvsMHH3xQW/UQERE9PD2Un2+Y9erIysoKPj4+0vsvv/wSarUaS5YswUcffQSg5qel/vooAoVCoXW3/qpSKpVatf7VU3taasCAAdiwYQPH1xARUe1RKHQ+PWQsFAoFlEol7t27J7XV9LRUXXkqT0sBQPPmzTFz5kzs3r0bAQEBsPrLD9+bb76pt+KIiIiMXWFhIbKzswE8PC2VkJCA/Px8rXGoNT0tpS9CCKnWRzk5OUGpVOp8WiorKwu3bt1CVlYWSkpKkJGRAQDw8fEpN7anLukcbpYuXQpbW1scPHgQBw8e1JqmUCgYboiI6KmSkpICV1dXAA/HtLRq1Qrr1q2r9JJsQ8nLy5NqfZRGo3niYOSKTJs2DStWrJDed+jQAcDDq7sMuf0KIYQw2NoNIC8vD2q1Grm5ubCxsTF0OURET7379+/j/Pnz8Pb2rtHdcqn+q+xnQZfvb4M+FZyIiIhI33Q+LfX3v/+90unLli2rdjFERERENaVzuLl9+7bW+wcPHuD48ePIyclBz5499VYYERERUXXoHG7Wr19frq20tBRjxoxBs2bN9FIUERERUXXpZcyNUqlETEwM5s+fr4/FEREREVWb3gYUZ2Zmori4WF+LIyIiIqoWnU9LxcTEaL0XQkCj0eDHH39EZGSk3gojIiIiqg6dw83hw4e13iuVSjg6OmLu3LlPvJKKiIiIqLbpHG7S0tJqow4iIiIivdB5zM358+dx5syZcu1nzpzBhQsX9FETERHRUysuLg7+/v46zVNQUIBBgwbBxsYGCoUCOTk5tVJbfaFzuImKisKePXvKte/duxdRUVH6qImIiKheiIqKgkKhkF6NGjVC7969cfTo0Wovc/LkyUhNTdVpnhUrVmDnzp3Ys2cPNBoN1Gp1uT5JSUlatZa9avLICy8vr3LLmz17drWXpy86h5vDhw+ja9eu5dqfffZZ6WmgRERET4vevXtDo9FAo9EgNTUVDRo0QL9+/aq9PGtrazRq1EineTIzM9G6dWu0bdsWLi4uUCgUFfazsbGRai17Xbx4sdq1AsDMmTO1ljdhwoQaLU8fdB5zo1AocOfOnXLtubm5KCkp0UtRRERE9YVKpZKeqO3i4oKpU6eiW7duuH79OhwdHXVeXlxcHDZs2CAdMIiKikJOTg6ee+45zJ07F0VFRRg6dCgWLFgAU1NTdO/eHb/88guAh9/RwcHB2LFjR4XLVigU1Xr6d2UaNmyo92XWlM5Hbp5//nnEx8drBZmSkhLEx8fjueee02txRET0dBJC4G7R3Tp/CSFqVHd+fj5WrlwJHx8fraMvvr6+sLa2fuwrLCys0uWmpaUhMzMTaWlpWLFiBZKSkpCUlAQASE5ORnR0NIKCgqDRaJCcnFzt+mfNmlVpndbW1sjKytKaZ/bs2WjUqBE6dOiATz/91CjueafzkZtPPvkEzz//PFq2bIlu3boBAHbu3Im8vDxs375d7wUSEdHTp+BBAazjret8vfmx+bAys9Jpnk2bNsHa+mGtd+/ehaurKzZt2gSl8n/HDzZv3owHDx48dhkWFhaVrsPOzg4JCQkwMTFBq1at0LdvX6SmpiI6Ohr29vawtLSEmZnZE4+g5ObmSrWW6datG7Zs2QIAGD16NIYMGVLpMtzc3KS/v/nmm+jYsSPs7e2xZ88exMbGQqPRYN68eZUuo7bpHG7atGmDo0ePIiEhAUeOHIGFhQVGjBiB8ePHw97evjZqJCIiMlo9evRAYmIigIcPl160aBHCwsKwb98+eHp6AoD0Z3X5+vrCxMREeu/q6opjx47pvJyGDRvi0KFDWm2PBit7e3udvssfvbFvu3btYGZmhlGjRiE+Ph4qlUrn+vRF53ADPExts2bN0nctREREAABLU0vkx+YbZL26srKygo+Pj/T+yy+/hFqtxpIlS/DRRx8BeBhOKhu4++jRk4qYmppqvVcoFCgtLdW5VqVSqVXrX82aNeuJ3+8nTpyAh4dHhdMCAwNRXFyMCxcuoGXLljrXpy86h5vly5fD2toagwcP1mpft24dCgoK+AgGIiKqMYVCofPpIWOhUCigVCpx7949qa2mp6Xqiq6npf4qIyMDSqUSTk5O+i5NJzqHm/j4eCxevLhcu5OTE9544w2GGyIieqoUFhYiOzsbwMPTUgkJCcjPz0d4eLjUp6anpfRFCCHV+ignJycolUqdTkulp6dj79696NGjBxo2bIj09HRMmjQJr776Kuzs7PRduk50DjdZWVnw9vYu1+7p6VluBDUREZHcpaSkwNXVFcDDMS2tWrXCunXr0L17d8MWVoG8vDyp1kdpNBqdL+dWqVRYs2YN4uLiUFhYCG9vb0yaNKncA7YNQSF0vO7Nw8MDCQkJeOmll7Tav//+e4wbNw5//vmnXgvUt7y8PKjVauTm5sLGxsbQ5RARPfXu37+P8+fPw9vbu0Z3y6X6r7KfBV2+v3W+z82wYcPw5ptvIi0tDSUlJSgpKcH27dsxceJEDB06VNfFEREREemVzqelPvzwQ1y4cAEvvPACGjR4OHtpaSlGjBiBjz/+WO8FEhEREelC53BjZmaGtWvX4qOPPkJGRgYsLCzg5+dnNIOliIiI6OlWrfvcAEDz5s3RvHlzAA/PgyUmJmLp0qU4cOCA3oojIiIi0lW1ww3w8FkXy5YtQ3JyMtRqNV5++WV91UVERERULTqHm8uXLyMpKQnLly9HTk4Obt++ja+//hpDhgx57CPWiYiIiOpKla+W+u6779CnTx+0bNkSGRkZmDt3Lq5cuQKlUgk/Pz8GGyIiIjIKVT5yExERgSlTpmDt2rVo2LBhbdZEREREVG1VPnLz+uuvY+HChejduze++OIL3L59uzbrIiIiIqqWKoebxYsXQ6PR4I033sDq1avh6uqK/v37QwhRrSeTEhERUXlxcXHw9/fXaZ6CggIMGjQINjY2UCgUyMnJqZXa6gud7lBsYWGByMhI/PLLLzh27Bh8fX3h7OyMrl274pVXXkFycnJt1UlERGR0oqKioFAopFejRo3Qu3dvHD16tNrLnDx5MlJTU3WaZ8WKFdi5cyf27NkDjUYDtVpdrk9SUpJWrWWvmjzy4uOPP0aXLl1gaWkJW1vbCvtkZWWhb9++sLS0hJOTE9555x0UFxdXe51VofPjF8o0b94cs2bNwqVLl7By5UoUFBRg2LBh+qyNiIjI6PXu3RsajQYajQapqalo0KAB+vXrV+3lWVtbo1GjRjrNk5mZidatW6Nt27ZwcXF57EU+NjY2Uq1lr4sXL1a71qKiIgwePBhjxoypcHpJSQn69u2LoqIi7NmzBytWrEBSUhKmTZtW7XVWRY3ucwMASqUS4eHhCA8Px7Vr1/RRExERUb2hUqmkJ2q7uLhg6tSp6NatG65fvw5HR0edlxcXF4cNGzYgIyMDwMOjQzk5OXjuuecwd+5cFBUVYejQoViwYAFMTU3RvXt3/PLLLwAAhUKB4OBg7Nixo8JlKxQKnZ/+XZkZM2YAeHhUqCI///wzTpw4gW3btsHZ2Rn+/v748MMPMWXKFMTFxcHMzExvtTyqxuHmUU5OTvpcHBERPaWEAAoK6n69lpZATe5skp+fj5UrV8LHx0fr6Iuvr2+lR0i6deuGLVu2PHZ6WloaXF1dkZaWhrNnzyIiIgL+/v6Ijo5GcnIypk6diuPHjyM5OblGgWHWrFmYNWtWpX1OnDgBDw+PKi0vPT0dfn5+cHZ2ltpCQ0MxZswY/P777+jQoUO1a62MXsMNERGRPhQUANbWdb/e/HzAykq3eTZt2gTr/y/27t27cHV1xaZNm6BU/m/kx+bNm/HgwYPHLsPCwqLSddjZ2SEhIQEmJiZo1aoV+vbti9TUVERHR8Pe3h6WlpYwMzN74lGZ3NxcqdYyjwar0aNHY8iQIZUuw83NrdLpj8rOztYKNgCk99nZ2VVejq4YboiIiGqgR48eSExMBADcvn0bixYtQlhYGPbt2yc9VLqmD5f29fWFiYmJ9N7V1RXHjh3TeTkNGzbEoUOHtNoeDVb29vawt7evfqFGguGGiIiMjqXlw6MohlivrqysrODj4yO9//LLL6FWq7FkyRJ89NFHAGp+WsrU1FTrvUKhqNZtWJRKpVatf6Xv01IuLi7Yt2+fVtvVq1elabVF53DTtGlT7N+/v9xI7pycHHTs2BHnzp3TW3FERPR0Uih0Pz1kLBQKBZRKJe7duye11fS0VF3R92mpoKAgfPzxx7h27Zo0Lnfr1q2wsbFBmzZtalRrZXQONxcuXEBJSUm59sLCQly+fFkvRREREdUXhYWF0viR27dvIyEhAfn5+QgPD5f61PS0lL4IISoc6+Lk5ASlUqnzaamsrCzcunULWVlZKCkpka7w8vHxgbW1NXr16oU2bdrgtddew5w5c5CdnY33338f48aNg0ql0tdmlVPlcLNx40bp7z/99JPWDYJKSkqQmpoKLy8vvRZHRERk7FJSUuDq6grg4ZiWVq1aYd26dejevbthC6tAXl6eVOujNBpNtU4TTZs2DStWrJDel139lJaWhu7du8PExASbNm3CmDFjEBQUBCsrK0RGRmLmzJnV34gqUAghRFU6lo36VigU+Osspqam8PLywty5c2t046K6kJeXB7VajdzcXNjY2Bi6HCKip979+/dx/vx5eHt71+huuVT/VfazoMv3d5WP3JQNXPL29sb+/fvh4OBQjbKJiIiIapfOY27Onz9fri0nJ+exz5QgIiIiqks6P1vqk08+wdq1a6X3gwcPhr29PRo3bowjR47otTgiIiIiXekcbr744gu4u7sDeHg517Zt25CSkoKwsDC888471Spi4cKF8PLygrm5OQIDA8tdE/84a9asgUKhwIABA6q1XiIiIpIfncNNdna2FG42bdqEIUOGoFevXnj33Xexf/9+nQtYu3YtYmJiMH36dBw6dAjt27dHaGjoEx/CeeHCBUyePBndunXTeZ1EREQkXzqHGzs7O1y6dAnAw8vfQkJCADy8dr6i+988ybx58xAdHY2RI0eiTZs2+OKLL2BpaYlly5Y9dp6SkhIMHz4cM2bMQNOmTXVeJxERGZ/q3HGX5KWKF3A/kc4DigcOHIhXXnkFzZs3x82bNxEWFgYAOHz4cKW3dK5IUVERDh48iNjYWKlNqVQiJCQE6enpj51v5syZcHJywuuvv46dO3fquglERGREzMzMoFQqceXKFTg6OsLMzAyKmjyam+olIQSuX78OhUJR7nETutI53MyfPx9eXl64dOkS5syZIz1dVKPRYOzYsTot68aNGygpKanwiaGnTp2qcJ5du3Zh6dKl0l0Qn6SwsBCFhYXS+7y8PJ1qJCKi2qVUKuHt7Q2NRoMrV64YuhwyIIVCgSZNmmg9JLQ6dA43pqammDx5crn2SZMm1aiQqrhz5w5ee+01LFmypMr32YmPj8eMGTNquTIiIqoJMzMzeHh4oLi4uFpDHEgeTE1NaxxsgGo+Ffyrr77C4sWLce7cOaSnp8PT0xMLFiyAt7c3+vfvX+XlODg4wMTERHpCaJmrV69WeBvozMxMXLhwQet5HWXnaBs0aIDTp0+jWbNmWvPExsYiJiZGep+XlycNiCYiIuNRdjqipqckiHQeUJyYmIiYmBiEhYUhJydHSti2trZYsGCBTssyMzNDQEAAUlNTpbbS0lKkpqYiKCioXP9WrVrh2LFjyMjIkF4vvfQSevTogYyMjApDi0qlgo2NjdaLiIiI5EvnIzeff/45lixZggEDBmD27NlSe6dOnSo8XfUkMTExiIyMRKdOndC5c2csWLAAd+/exciRIwEAI0aMQOPGjREfHw9zc3O0bdtWa/6yOyP/tZ2IiIieTtV6/ELZUz8fpVKpcPfuXZ0LiIiIwPXr1zFt2jRkZ2fD398fKSkp0iDjrKws6aGdRERERE+ic7jx9vZGRkYGPD09tdpTUlLQunXrahUxfvx4jB8/vsJpO3bsqHTepKSkaq2TiIiI5KnK4WbmzJmYPHkyYmJiMG7cONy/fx9CCOzbtw+rV69GfHw8vvzyy9qslYiIiOiJFKKKtwM0MTGBRqOBk5MTVq1ahbi4OGRmZgIA3NzcMGPGDLz++uu1Wqw+5OXlQa1WIzc3l4OLiYiI6gldvr+rHG6USiWys7Ph5OQktRUUFCA/P1+rzdgx3BAREdU/unx/6zTm5q+3w7a0tISlpaXuFRIRERHVEp3CTYsWLZ74vI9bt27VqCAiIiKimtAp3MyYMQNqtbq2aiEiIiKqMZ3CzdChQ+vV+BoiIiJ6+lT57nh8/DwRERHVB1UON1W8qIqIiIjIoKp8Wqrs6dtERERExowPbSIiIiJZYbghIiIiWWG4ISIiIllhuCEiIiJZYbghIiIiWWG4ISIiIllhuCEiIiJZYbghIiIiWWG4ISIiIllhuCEiIiJZYbghIiIiWWG4ISIiIllhuCEiIiJZYbghIiIiWWG4ISIiIllhuCEiIiJZYbghIiIiWWG4ISIiIllhuCEiIiJZYbghIiIiWWG4ISIiIllhuCEiIiJZYbghIiIiWWG4ISIiIllhuCEiIiJZYbghIiIiWWG4ISIiIllhuCEiIiJZYbghIiIiWWG4ISIiIllhuCEiIiJZYbghIiIiWWG4ISIiIllhuCEiIiJZYbghIiIiWWG4ISIiIllhuCEiIiJZYbghIiIiWWG4ISIiIllhuCEiIiJZYbghIiIiWWG4ISIiIllhuCEiIiJZYbghIiIiWWG4ISIiIllhuCEiIiJZYbghIiIiWTGKcLNw4UJ4eXnB3NwcgYGB2Ldv32P7LlmyBN26dYOdnR3s7OwQEhJSaX8iIiJ6uhg83KxduxYxMTGYPn06Dh06hPbt2yM0NBTXrl2rsP+OHTswbNgwpKWlIT09He7u7ujVqxcuX75cx5UTERGRMVIIIYQhCwgMDMQzzzyDhIQEAEBpaSnc3d0xYcIETJ069Ynzl5SUwM7ODgkJCRgxYsQT++fl5UGtViM3Nxc2NjY1rp+IiIhqny7f3wY9clNUVISDBw8iJCREalMqlQgJCUF6enqVllFQUIAHDx7A3t6+wumFhYXIy8vTehEREZF8GTTc3LhxAyUlJXB2dtZqd3Z2RnZ2dpWWMWXKFLi5uWkFpEfFx8dDrVZLL3d39xrXTURERMbL4GNuamL27NlYs2YN1q9fD3Nz8wr7xMbGIjc3V3pdunSpjqskIiKiutTAkCt3cHCAiYkJrl69qtV+9epVuLi4VDrvZ599htmzZ2Pbtm1o167dY/upVCqoVCq91EtERETGz6BHbszMzBAQEIDU1FSprbS0FKmpqQgKCnrsfHPmzMGHH36IlJQUdOrUqS5KJSIionrCoEduACAmJgaRkZHo1KkTOnfujAULFuDu3bsYOXIkAGDEiBFo3Lgx4uPjAQCffPIJpk2bhq+//hpeXl7S2Bxra2tYW1sbbDuIiIjIOBg83EREROD69euYNm0asrOz4e/vj5SUFGmQcVZWFpTK/x1gSkxMRFFREf72t79pLWf69OmIi4ury9KJiIjICBn8Pjd1jfe5ISIiqn/qzX1uiIiIiPSN4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4UZPjl49ileTX8W4H8cZuhQiIqKnGsONntwpvINVx1bhq6Nf4d6De4Yuh4iI6KnFcKMnQe5B8FB74E7RHWw5u8XQ5RARET21GG70RKlQIsI3AgCw5vgaA1dDRET09GK40aOhbYcCAH744wfcKbxj4GqIiIieTkYRbhYuXAgvLy+Ym5sjMDAQ+/btq7T/unXr0KpVK5ibm8PPzw+bN2+uo0or18GlA1o0aoH7xfex8fRGQ5dDRET0VGpg6ALWrl2LmJgYfPHFFwgMDMSCBQsQGhqK06dPw8nJqVz/PXv2YNiwYYiPj0e/fv3w9ddfY8CAATh06BDatm1rgC34f0JAUVCAoS0GYmb6bHx1OAnPOXQ0XD1EREQGomqggoujN6BQGGT9CiGEMMia/19gYCCeeeYZJCQkAABKS0vh7u6OCRMmYOrUqeX6R0RE4O7du9i0aZPU9uyzz8Lf3x9ffPHFE9eXl5cHtVqN3Nxc2NjY6G9D7t4FrK1xwhHw5dXgRET0FAu6BOz5Vz5gZaW3Zery/W3QIzdFRUU4ePAgYmNjpTalUomQkBCkp6dXOE96ejpiYmK02kJDQ7Fhw4YK+xcWFqKwsFB6n5eXV/PCK9HmOjDsGLC+Va2uhoiIyGiZlRh2/QYNNzdu3EBJSQmcnZ212p2dnXHq1KkK58nOzq6wf3Z2doX94+PjMWPGDP0UXBlLSyA/HwDwde2vjYiIyLhZWhps1QYfc1PbYmNjtY705OXlwd3dXf8rUij0eviNiIiIqseg4cbBwQEmJia4evWqVvvVq1fh4uJS4TwuLi469VepVFCpVPopmIiIiIyeQS8FNzMzQ0BAAFJTU6W20tJSpKamIigoqMJ5goKCtPoDwNatWx/bn4iIiJ4uBj8tFRMTg8jISHTq1AmdO3fGggULcPfuXYwcORIAMGLECDRu3Bjx8fEAgIkTJyI4OBhz585F3759sWbNGhw4cAD/+c9/DLkZREREZCQMHm4iIiJw/fp1TJs2DdnZ2fD390dKSoo0aDgrKwtK5f8OMHXp0gVff/013n//fbz33nto3rw5NmzYYNh73BAREZHRMPh9bupard3nhoiIiGqNLt/fRvH4BSIiIiJ9YbghIiIiWWG4ISIiIllhuCEiIiJZYbghIiIiWWG4ISIiIllhuCEiIiJZYbghIiIiWTH4HYrrWtk9C/Py8gxcCREREVVV2fd2Ve49/NSFmzt37gAA3N3dDVwJERER6erOnTtQq9WV9nnqHr9QWlqKK1euoGHDhlAoFHpZZl5eHtzd3XHp0iVZPtJB7tsHyH8b5b59ALdRDuS+fQC3sSaEELhz5w7c3Ny0njlZkafuyI1SqUSTJk1qZdk2Njay/WEF5L99gPy3Ue7bB3Ab5UDu2wdwG6vrSUdsynBAMREREckKww0RERHJCsONHqhUKkyfPh0qlcrQpdQKuW8fIP9tlPv2AdxGOZD79gHcxrry1A0oJiIiInnjkRsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYabGlq4cCG8vLxgbm6OwMBA7Nu3z9AlVUl8fDyeeeYZNGzYEE5OThgwYABOnz6t1ad79+5QKBRar9GjR2v1ycrKQt++fWFpaQknJye88847KC4urstNeay4uLhy9bdq1Uqafv/+fYwbNw6NGjWCtbU1Bg0ahKtXr2otw5i3z8vLq9z2KRQKjBs3DkD93H+//vorwsPD4ebmBoVCgQ0bNmhNF0Jg2rRpcHV1hYWFBUJCQnDmzBmtPrdu3cLw4cNhY2MDW1tbvP7668jPz9fqc/ToUXTr1g3m5uZwd3fHnDlzanvTJJVt44MHDzBlyhT4+fnBysoKbm5uGDFiBK5cuaK1jIr2/ezZs7X6GGobn7QPo6KiytXeu3dvrT71eR8CqPDfpUKhwKeffir1MeZ9WJXvB339/tyxYwc6duwIlUoFHx8fJCUl6WcjBFXbmjVrhJmZmVi2bJn4/fffRXR0tLC1tRVXr141dGlPFBoaKpYvXy6OHz8uMjIyRJ8+fYSHh4fIz8+X+gQHB4vo6Gih0WikV25urjS9uLhYtG3bVoSEhIjDhw+LzZs3CwcHBxEbG2uITSpn+vTpwtfXV6v+69evS9NHjx4t3N3dRWpqqjhw4IB49tlnRZcuXaTpxr59165d09q2rVu3CgAiLS1NCFE/99/mzZvFP//5T5GcnCwAiPXr12tNnz17tlCr1WLDhg3iyJEj4qWXXhLe3t7i3r17Up/evXuL9u3bi99++03s3LlT+Pj4iGHDhknTc3NzhbOzsxg+fLg4fvy4WL16tbCwsBCLFy82+Dbm5OSIkJAQsXbtWnHq1CmRnp4uOnfuLAICArSW4enpKWbOnKm1bx/9t2vIbXzSPoyMjBS9e/fWqv3WrVtaferzPhRCaG2bRqMRy5YtEwqFQmRmZkp9jHkfVuX7QR+/P8+dOycsLS1FTEyMOHHihPj888+FiYmJSElJqfE2MNzUQOfOncW4ceOk9yUlJcLNzU3Ex8cbsKrquXbtmgAgfvnlF6ktODhYTJw48bHzbN68WSiVSpGdnS21JSYmChsbG1FYWFib5VbJ9OnTRfv27SuclpOTI0xNTcW6deuktpMnTwoAIj09XQhh/Nv3VxMnThTNmjUTpaWlQoj6v//++qVRWloqXFxcxKeffiq15eTkCJVKJVavXi2EEOLEiRMCgNi/f7/UZ8uWLUKhUIjLly8LIYRYtGiRsLOz09rGKVOmiJYtW9byFpVX0RfjX+3bt08AEBcvXpTaPD09xfz58x87j7Fs4+PCTf/+/R87jxz3Yf/+/UXPnj212urLPhSi/PeDvn5/vvvuu8LX11drXRERESI0NLTGNfO0VDUVFRXh4MGDCAkJkdqUSiVCQkKQnp5uwMqqJzc3FwBgb2+v1b5q1So4ODigbdu2iI2NRUFBgTQtPT0dfn5+cHZ2ltpCQ0ORl5eH33//vW4Kf4IzZ87Azc0NTZs2xfDhw5GVlQUAOHjwIB48eKC1/1q1agUPDw9p/9WH7StTVFSElStX4u9//7vWA2Hr+/571Pnz55Gdna21z9RqNQIDA7X2ma2tLTp16iT1CQkJgVKpxN69e6U+zz//PMzMzKQ+oaGhOH36NG7fvl1HW1N1ubm5UCgUsLW11WqfPXs2GjVqhA4dOuDTTz/VOtxv7Nu4Y8cOODk5oWXLlhgzZgxu3rwpTZPbPrx69Sp+/PFHvP766+Wm1Zd9+NfvB339/kxPT9daRlkffXyHPnUPztSXGzduoKSkRGvHAYCzszNOnTploKqqp7S0FG+99Ra6du2Ktm3bSu2vvPIKPD094ebmhqNHj2LKlCk4ffo0kpOTAQDZ2dkVbn/ZNEMLDAxEUlISWrZsCY1GgxkzZqBbt244fvw4srOzYWZmVu4Lw9nZWard2LfvURs2bEBOTg6ioqKktvq+//6qrKaKan50nzk5OWlNb9CgAezt7bX6eHt7l1tG2TQ7O7taqb867t+/jylTpmDYsGFaDyB888030bFjR9jb22PPnj2IjY2FRqPBvHnzABj3Nvbu3RsDBw6Et7c3MjMz8d577yEsLAzp6ekwMTGR3T5csWIFGjZsiIEDB2q115d9WNH3g75+fz6uT15eHu7duwcLC4tq181wQxg3bhyOHz+OXbt2abW/8cYb0t/9/Pzg6uqKF154AZmZmWjWrFldl6mzsLAw6e/t2rVDYGAgPD098c0339ToH40xWrp0KcLCwuDm5ia11ff997R78OABhgwZAiEEEhMTtabFxMRIf2/Xrh3MzMwwatQoxMfHG/1t/YcOHSr93c/PD+3atUOzZs2wY8cOvPDCCwasrHYsW7YMw4cPh7m5uVZ7fdmHj/t+MHY8LVVNDg4OMDExKTc6/OrVq3BxcTFQVbobP348Nm3ahLS0NDRp0qTSvoGBgQCAs2fPAgBcXFwq3P6yacbG1tYWLVq0wNmzZ+Hi4oKioiLk5ORo9Xl0/9WX7bt48SK2bduGf/zjH5X2q+/7r6ymyv7Nubi44Nq1a1rTi4uLcevWrXq1X8uCzcWLF7F161atozYVCQwMRHFxMS5cuACgfmxjmaZNm8LBwUHr51IO+xAAdu7cidOnTz/x3yZgnPvwcd8P+vr9+bg+NjY2Nf4PKMNNNZmZmSEgIACpqalSW2lpKVJTUxEUFGTAyqpGCIHx48dj/fr12L59e7nDnxXJyMgAALi6ugIAgoKCcOzYMa1fRGW/iNu0aVMrdddEfn4+MjMz4erqioCAAJiammrtv9OnTyMrK0vaf/Vl+5YvXw4nJyf07du30n71ff95e3vDxcVFa5/l5eVh7969WvssJycHBw8elPps374dpaWlUrgLCgrCr7/+igcPHkh9tm7dipYtWxrF6YyyYHPmzBls27YNjRo1euI8GRkZUCqV0ukcY9/GR/3555+4efOm1s9lfd+HZZYuXYqAgAC0b9/+iX2NaR8+6ftBX78/g4KCtJZR1kcv36E1HpL8FFuzZo1QqVQiKSlJnDhxQrzxxhvC1tZWa3S4sRozZoxQq9Vix44dWpciFhQUCCGEOHv2rJg5c6Y4cOCAOH/+vPj+++9F06ZNxfPPPy8to+xSv169eomMjAyRkpIiHB0djeZS6bffflvs2LFDnD9/XuzevVuEhIQIBwcHce3aNSHEw0sZPTw8xPbt28WBAwdEUFCQCAoKkuY39u0T4uEVeh4eHmLKlCla7fV1/925c0ccPnxYHD58WAAQ8+bNE4cPH5auFJo9e7awtbUV33//vTh69Kjo379/hZeCd+jQQezdu1fs2rVLNG/eXOsy4pycHOHs7Cxee+01cfz4cbFmzRphaWlZZ5cRV7aNRUVF4qWXXhJNmjQRGRkZWv82y64w2bNnj5g/f77IyMgQmZmZYuXKlcLR0VGMGDHCKLaxsu27c+eOmDx5skhPTxfnz58X27ZtEx07dhTNmzcX9+/fl5ZRn/dhmdzcXGFpaSkSExPLzW/s+/BJ3w9C6Of3Z9ml4O+88444efKkWLhwIS8FNxaff/658PDwEGZmZqJz587it99+M3RJVQKgwtfy5cuFEEJkZWWJ559/Xtjb2wuVSiV8fHzEO++8o3WfFCGEuHDhgggLCxMWFhbCwcFBvP322+LBgwcG2KLyIiIihKurqzAzMxONGzcWERER4uzZs9L0e/fuibFjxwo7OzthaWkpXn75ZaHRaLSWYczbJ4QQP/30kwAgTp8+rdVeX/dfWlpahT+XkZGRQoiHl4N/8MEHwtnZWahUKvHCCy+U2/abN2+KYcOGCWtra2FjYyNGjhwp7ty5o9XnyJEj4rnnnhMqlUo0btxYzJ49u642sdJtPH/+/GP/bZbdv+jgwYMiMDBQqNVqYW5uLlq3bi1mzZqlFQ4MuY2VbV9BQYHo1auXcHR0FKampsLT01NER0eX+w9hfd6HZRYvXiwsLCxETk5OufmNfR8+6ftBCP39/kxLSxP+/v7CzMxMNG3aVGsdNaH4/w0hIiIikgWOuSEiIiJZYbghIiIiWWG4ISIiIllhuCEiIiJZYbghIiIiWWG4ISIiIllhuCEiIiJZYbghIqOgUCiwYcOGWl1HUlJSuScZP428vLywYMECQ5dBVGsYboiMTHZ2NiZMmICmTZtCpVLB3d0d4eHh5Z7BIjcajUbrSe41VdEXeEREBP744w+9reNxunfvDoVCAYVCAXNzc7Ro0QLx8fHgPVOJ6kYDQxdARP9z4cIFdO3aFba2tvj000/h5+eHBw8e4KeffsK4ceNw6tQpQ5dYa+riSccWFhY1ftpwVUVHR2PmzJkoLCzE9u3b8cYbb8DW1hZjxoypk/UTPc145IbIiIwdOxYKhQL79u3DoEGD0KJFC/j6+iImJga//fab1C8rKwv9+/eHtbU1bGxsMGTIEFy9elWaHhcXB39/fyxbtgweHh6wtrbG2LFjUVJSgjlz5sDFxQVOTk74+OOPtdavUCiwePFi9OvXD5aWlmjdujXS09Nx9uxZdO/eHVZWVujSpQsyMzOleaKiojBgwACt5bz11lvo3r279L579+5488038e6778Le3h4uLi6Ii4srt+5HT0v9+eefGDZsGOzt7WFlZYVOnTph7969AIDMzEz0798fzs7OsLa2xjPPPINt27Zpre/ixYuYNGmSdAQFqPi0VGJiIpo1awYzMzO0bNkSX331Vbm6vvzyS7z88suwtLRE8+bNsXHjxop34CMsLS3h4uICT09PjBw5Eu3atcPWrVul6bdv38aIESNgZ2cHS0tLhIWF4cyZM9L0sn34qAULFsDLy0t6X/bZf/bZZ3B1dUWjRo0wbtw4rSdJX7t2DeHh4bCwsIC3tzdWrVqltUwhBOLi4uDh4QGVSgU3Nze8+eabT9w+ImPGcENkJG7duoWUlBSMGzcOVlZW5aaXfSmXlpaif//+uHXrFn755Rds3boV586dQ0REhFb/zMxMbNmyBSkpKVi9ejWWLl2Kvn374s8//8Qvv/yCTz75BO+//74UGMp8+OGHGDFiBDIyMtCqVSu88sorGDVqFGJjY3HgwAEIITB+/Hidt2/FihWwsrLC3r17MWfOHMycOVPry/5R+fn5CA4OxuXLl7Fx40YcOXIE7777LkpLS6Xpffr0QWpqKg4fPozevXsjPDwcWVlZAIDk5GQ0adIEM2fOhEajgUajqXA969evx8SJE/H222/j+PHjGDVqFEaOHIm0tDStfjNmzMCQIUNw9OhR9OnTB8OHD8etW7eqtN1CCOzcuROnTp2CmZmZ1B4VFYUDBw5g48aNSE9PhxACffr00QomVZGWlobMzEykpaVhxYoVSEpKQlJSktZ6Ll26hLS0NHz77bdYtGgRrl27Jk3/7rvvMH/+fCxevBhnzpzBhg0b4Ofnp1MNREZHL4/fJKIa27t3rwAgkpOTK+33888/CxMTE5GVlSW1/f777wKA2LdvnxBCiOnTpwtLS0uRl5cn9QkNDRVeXl6ipKREamvZsqWIj4+X3gMQ77//vvQ+PT1dABBLly6V2lavXi3Mzc2l95GRkaJ///5aNU6cOFEEBwdL74ODg8Vzzz2n1eeZZ54RU6ZM0Vr3+vXrhRAPn6jcsGFDcfPmzUo/i0f5+vqKzz//XHrv6ekp5s+fr9Vn+fLlQq1WS++7dOkioqOjtfoMHjxY9OnTR6uuRz+T/Px8AUBs2bLlsbUEBwcLU1NTYWVlJUxNTQUAYW5uLnbv3i2EEOKPP/4QAKT3Qghx48YNYWFhIb755hshxMN92L59e63lzp8/X3h6ekrvIyMjhaenpyguLtaqPyIiQgghxOnTp7V+LoQQ4uTJkwKA9NnMnTtXtGjRQhQVFT12e4jqGx65ITISooqDTU+ePAl3d3e4u7tLbW3atIGtrS1OnjwptXl5eaFhw4bSe2dnZ7Rp0wZKpVKr7dH/xQNAu3bttKYD0PqfvLOzM+7fv4+8vLwqbln55QKAq6truXWXycjIQIcOHWBvb1/h9Pz8fEyePBmtW7eGra0trK2tcfLkSenITVWdPHkSXbt21Wrr2rWr1uf419qtrKxgY2Pz2NrLDB8+HBkZGdi9ezfCwsLwz3/+E126dJHW26BBAwQGBkr9GzVqhJYtW5Zb95P4+vrCxMREev/o51q2noCAAGl6q1attE7NDR48GPfu3UPTpk0RHR2N9evXo7i4WKcaiIwNww2RkWjevDkUCoXeBg2bmppqvVcoFBW2lZ3qqWi+srEqFbWVzadUKssFs4pOrVRl3WWeNOh38uTJWL9+PWbNmoWdO3ciIyMDfn5+KCoqqnS+6tKl9jJqtRo+Pj545pln8M033yAhIUFrXNCT1MbnWhF3d3ecPn0aixYtgoWFBcaOHYvnn39e59NjRMaE4YbISNjb2yM0NBQLFy7E3bt3y03PyckBALRu3RqXLl3CpUuXpGknTpxATk4O2rRpU1flShwdHcuNacnIyKjRMtu1a4eMjIzHjmvZvXs3oqKi8PLLL8PPzw8uLi64cOGCVh8zMzOUlJRUup7WrVtj9+7d5Zat78/R2toaEydOxOTJkyGEQOvWrVFcXKw13unmzZs4ffq0tG5HR0dkZ2drBRxdP9dWrVqhuLgYBw8elNpOnz4t/SyVsbCwQHh4OP79739jx44dSE9Px7Fjx3TfUCIjwXBDZEQWLlyIkpISdO7cGd999x3OnDmDkydP4t///jeCgoIAACEhIfDz88Pw4cNx6NAh7Nu3DyNGjEBwcDA6depU5zX37NkTBw4cwH//+1+cOXMG06dPx/Hjx2u0zGHDhsHFxQUDBgzA7t27ce7cOXz33XdIT08H8PAoV3JyMjIyMnDkyBG88sor5Y5WeHl54ddff8Xly5dx48aNCtfzzjvvICkpCYmJiThz5gzmzZuH5ORkTJ48uUb1V2TUqFH4448/8N1336F58+bo378/oqOjsWvXLhw5cgSvvvoqGjdujP79+wN4eMXX9evXMWfOHGRmZmLhwoXYsmWLTuts2bIlevfujVGjRmHv3r04ePAg/vGPf2gdGUtKSsLSpUtx/PhxnDt3DitXroSFhQU8PT31uv1EdYnhhsiING3aFIcOHUKPHj3w9ttvo23btnjxxReRmpqKxMREAA9PO3z//fews7PD888/j5CQEDRt2hRr1641SM2hoaH44IMP8O677+KZZ57BnTt3MGLEiBot08zMDD///DOcnJzQp08f+Pn5Yfbs2dLYknnz5sHOzg5dunRBeHg4QkND0bFjR61lzJw5ExcuXECzZs3g6OhY4XoGDBiAf/3rX/jss8/g6+uLxYsXY/ny5VqXseuLvb09RowYgbi4OJSWlmL58uUICAhAv379EBQUBCEENm/eLJ1mat26NRYtWoSFCxeiffv22LdvX7VC1/Lly+Hm5obg4GAMHDgQb7zxBpycnKTptra2WLJkCbp27Yp27dph27Zt+OGHH9CoUSO9bTtRXVOIqo5iJCIiIqoHeOSGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhk5f8AbY4ZS5xEdhcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(3) # to make sure initial weights are same for each run, for reproducibility guarantee \n",
    "\n",
    "K = 20 # number of clients\n",
    "number_of_pca_dim = 2 # number of new projected features of the data\n",
    "\n",
    "max_round = 2000 # Communication Rounds a.k.a number of update of weights in the server\n",
    "test_every_round = 10 # when to test of the weights of the server\n",
    "x_axis = np.linspace(test_every_round, max_round, int(max_round/test_every_round))\n",
    "print(f\"Testing at {x_axis} communication rounds.\")\n",
    "\n",
    "E_list = [1, 5, 10] # number of local epochs\n",
    "color_list = [\"-r\", \"-g\", \"-b\"]\n",
    "for E, c in zip(E_list, color_list):\n",
    "    acc_list = federated_averaging(K, E, number_of_pca_dim, max_round, test_every_round)\n",
    "    plt.plot(x_axis, acc_list, c, label=f\"B=inf E={E}\")\n",
    "    print(f\"\\nTesting acc E={E} {acc_list}\\n\")\n",
    "\n",
    "plt.xlabel('Communication Rounds')\n",
    "plt.ylabel('Test Accuracy') \n",
    "plt.title('Federated Averaging')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: PCA ksmndan emin ol\n",
    "# TODO: buraya discussion yaz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Feature selection using Variance Threshold (10 points)\n",
    "\n",
    "In this part, we will use scikit-learn library for training SVM. To remind you, you can install the scikit-learn using following commands:\n",
    "\n",
    "        > python3 -m pip install scikit-learn\n",
    "        > conda install -c conda-forge scikit-learn\n",
    "        \n",
    "There are lots of machine learning techniques that are available in scikit-learn library. In this problem we will use the **SVM** classifier with linear kernel and implement Variance Threshold feature selection method from scratch.\n",
    "   \n",
    "\n",
    "You can check the documentations on the internet to learn how to use SVM classifier and which parameters to use. Necessary functions are imported below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file is associated with the book\n",
    "# \"Machine Learning Refined\", Cambridge University Press, 2016.\n",
    "# by Jeremy Watt, Reza Borhani, and Aggelos Katsaggelos.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "import sklearn.datasets as ds\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will implement feature selection on handwritten digits dataset. In the following cell we load and examine dataset. As you can see the samples are 8 by 8 images where in each row of X, the images are kept as flatten vectors. Each feature represents a pixel (i.e 0th feature is (0, 0) pixel and 8th feature is (1, 0) pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:  1797\n",
      "Number of attributes:  64\n",
      "Classes:  [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1600x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "digit_data = ds.load_digits()\n",
    "print(\"Number of samples: \", digit_data.data.shape[0])\n",
    "print(\"Number of attributes: \", digit_data.data.shape[1])\n",
    "print(\"Classes: \", digit_data.target_names)\n",
    "\n",
    "c = digit_data.images[0]\n",
    "for i in range(1, 10):\n",
    "    c = np.concatenate((c, digit_data.images[i]), 1)\n",
    "\n",
    "plt.gray() \n",
    "plt.matshow(c)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we split the data into training and testing sets in order to train the models on training set and test them on unseen test set. Do not change the random state so we will get the same train and test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples:  1437\n",
      "Number of testing samples:  360\n"
     ]
    }
   ],
   "source": [
    "X, y = digit_data.data, digit_data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle = True, random_state=20)\n",
    "\n",
    "print(\"Number of training samples: \", X_train.shape[0])\n",
    "print(\"Number of testing samples: \", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In the following cell, you should complete the necessary train and test functions for SVM. Fill the specified parts only. Calculate the accuracy score as:\n",
    "\n",
    "<br>\n",
    "<center> $ Accuracy = \\frac{\\#correct \\ predictions}{\\#total \\ samples} $ </center>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y):\n",
    "    classifier = SVC(kernel=\"linear\")  # define the classifier\n",
    "    classifier.fit(X, y)  # fit the classifier on training set\n",
    "    \n",
    "    preds = classifier.predict(X)  # predict the labels for training set\n",
    "  \n",
    "    correct = 0\n",
    "    n = len(y)\n",
    "    for i in range(n):\n",
    "        if preds[i] == y[i]:\n",
    "            correct += 1\n",
    "    train_accuracy = correct/n  # calculate the accuracy (do not use built-in function)\n",
    "    \n",
    "    return classifier, train_accuracy\n",
    "\n",
    "def test(classifier, X, y):\n",
    "    preds = classifier.predict(X)  # predict the labels for test set\n",
    "    \n",
    "    correct = 0\n",
    "    n = len(y)\n",
    "    for i in range(n):\n",
    "        if preds[i] == y[i]:\n",
    "            correct += 1    \n",
    "    test_accuracy = correct/n  # calculate the accuracy on test set\n",
    "    \n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Next, use these function to train and test an SVM without feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc without feature selection:  1.0\n",
      "Test acc without feature selection:  0.975\n"
     ]
    }
   ],
   "source": [
    "# SVM classifier without feature selection\n",
    "svm, train_acc = train(X_train, y_train) # call train function with necessary parameters\n",
    "test_acc = test(svm, X_test, y_test)  # call test function with necessary parameters\n",
    "\n",
    "print(\"Train acc without feature selection: \", train_acc)\n",
    "print(\"Test acc without feature selection: \", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now, implement Variance Threshold feature selection method on the dataset. The Variance Threshold basicly follows these steps:\n",
    "  - Calculate the variances of each feature in the dataset. (Hint: You can use numpy for this)\n",
    "  - Eliminate the features that has variance less then the given threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_threshold(X, threshold=0):\n",
    "    selected = [] # keep the indexes of selected feature\n",
    "    eliminated = [] # keep the indexes of eliminated features\n",
    "    \n",
    "    #calculate variances of each feature and eliminate features with variance lower than threshold\n",
    "    n_features = X.shape[1] # number of features before applying variance threshold\n",
    "    for f in range(n_features):\n",
    "        var_f = np.var(X[:,f])\n",
    "        if var_f < threshold: # eliminate feature\n",
    "            eliminated.append(f)\n",
    "        else: # select feature\n",
    "            selected.append(f)\n",
    "    \n",
    "    print(\"Indexes of the eliminated features: \", eliminated) # print the indexes of eliminated features.\n",
    "\n",
    "    X_reduced = X[:,selected]\n",
    "    \n",
    "    print(\"Number of features for threshold = \", threshold, \"is :\", X_reduced.shape[1])\n",
    "    return X_reduced, selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_threshold_to_test(X, selected_feature_indexes):\n",
    "    X_reduced = X[:,selected_feature_indexes]\n",
    "    \n",
    "    return X_reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now, call the variance threshold function for **5** distinct threshold values and obtain **different set of features**. Then, train and test an SVM classifier on each set. Do not forget to apply the feature selection on the test set as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold =  0.33\n",
      "Indexes of the eliminated features:  [0, 8, 16, 23, 24, 31, 32, 39, 40, 47, 48, 56]\n",
      "Number of features for threshold =  0.33 is : 52\n",
      "Train acc with feature selection:  1.0\n",
      "Test acc with feature selection:  0.975\n",
      "\n",
      "\n",
      "Threshold =  5\n",
      "Indexes of the eliminated features:  [0, 1, 7, 8, 15, 16, 23, 24, 31, 32, 39, 40, 47, 48, 49, 55, 56, 57, 63]\n",
      "Number of features for threshold =  5 is : 45\n",
      "Train acc with feature selection:  1.0\n",
      "Test acc with feature selection:  0.975\n",
      "\n",
      "\n",
      "Threshold =  10\n",
      "Indexes of the eliminated features:  [0, 1, 7, 8, 15, 16, 23, 24, 25, 31, 32, 39, 40, 41, 47, 48, 49, 55, 56, 57, 63]\n",
      "Number of features for threshold =  10 is : 43\n",
      "Train acc with feature selection:  1.0\n",
      "Test acc with feature selection:  0.975\n",
      "\n",
      "\n",
      "Threshold =  20\n",
      "Indexes of the eliminated features:  [0, 1, 3, 4, 6, 7, 8, 9, 11, 14, 15, 16, 17, 22, 23, 24, 25, 30, 31, 32, 33, 38, 39, 40, 41, 46, 47, 48, 49, 55, 56, 57, 59, 62, 63]\n",
      "Number of features for threshold =  20 is : 29\n",
      "Train acc with feature selection:  1.0\n",
      "Test acc with feature selection:  0.9777777777777777\n",
      "\n",
      "\n",
      "Threshold =  30\n",
      "Indexes of the eliminated features:  [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 22, 23, 24, 25, 30, 31, 32, 33, 38, 39, 40, 41, 46, 47, 48, 49, 51, 52, 54, 55, 56, 57, 58, 59, 60, 62, 63]\n",
      "Number of features for threshold =  30 is : 21\n",
      "Train acc with feature selection:  1.0\n",
      "Test acc with feature selection:  0.9722222222222222\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "thresholds = [0.33, 5, 10, 20, 30]\n",
    "\n",
    "for th in thresholds:\n",
    "    print(\"Threshold = \", th)\n",
    "    X_reduced, selected = variance_threshold(X_train, th)\n",
    "    X_reduced_test = apply_threshold_to_test(X_test, selected)\n",
    "\n",
    "    svm, train_acc = train(X_reduced, y_train) # call train function with necessary parameters\n",
    "    test_acc = test(svm, X_reduced_test, y_test)  # call test function with necessary parameters\n",
    "\n",
    "    print(\"Train acc with feature selection: \", train_acc)\n",
    "    print(\"Test acc with feature selection: \", test_acc)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bonus Question (5 points)**\n",
    "Why the model performance varies with the number of selected features? Justify your answer with a toy example (i.e., using a simulated dataset). You can also refer to the results you got in Part 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since classifier is found by fitting it to the data, by removing some features we are automatically changing the classifier. As you can see from the MNIST example above, by deleting 35 features when the threshold is 20, we obtain slightly higher test accuracy than the one with threshold 10. If we would look at the weights of the classifier (or support vectors) the size and values will differ of these two."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
